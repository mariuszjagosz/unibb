{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JBuqF-4Dww1",
        "outputId": "da45665b-a63f-4cad-c2fa-e2bc1d7625db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.4087 - loss: 1.0933 - val_accuracy: 0.6333 - val_loss: 1.0087\n",
            "Epoch 2/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.4658 - loss: 1.0431 - val_accuracy: 0.7000 - val_loss: 0.9594\n",
            "Epoch 3/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5244 - loss: 0.9831 - val_accuracy: 0.7000 - val_loss: 0.9115\n",
            "Epoch 4/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6515 - loss: 0.9336 - val_accuracy: 0.7000 - val_loss: 0.8671\n",
            "Epoch 5/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5858 - loss: 0.9107 - val_accuracy: 0.7000 - val_loss: 0.8228\n",
            "Epoch 6/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6796 - loss: 0.8474 - val_accuracy: 0.7000 - val_loss: 0.7779\n",
            "Epoch 7/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6715 - loss: 0.8381 - val_accuracy: 0.7000 - val_loss: 0.7333\n",
            "Epoch 8/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6862 - loss: 0.7936 - val_accuracy: 0.7667 - val_loss: 0.6873\n",
            "Epoch 9/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6948 - loss: 0.7590 - val_accuracy: 0.8333 - val_loss: 0.6428\n",
            "Epoch 10/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7629 - loss: 0.6940 - val_accuracy: 0.8667 - val_loss: 0.5985\n",
            "Epoch 11/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7312 - loss: 0.6974 - val_accuracy: 0.9000 - val_loss: 0.5564\n",
            "Epoch 12/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8027 - loss: 0.6160 - val_accuracy: 0.9000 - val_loss: 0.5151\n",
            "Epoch 13/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7763 - loss: 0.5689 - val_accuracy: 0.9000 - val_loss: 0.4780\n",
            "Epoch 14/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8177 - loss: 0.5221 - val_accuracy: 0.9000 - val_loss: 0.4449\n",
            "Epoch 15/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8506 - loss: 0.5065 - val_accuracy: 0.9000 - val_loss: 0.4146\n",
            "Epoch 16/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7933 - loss: 0.5272 - val_accuracy: 0.9000 - val_loss: 0.3897\n",
            "Epoch 17/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8102 - loss: 0.5064 - val_accuracy: 0.9000 - val_loss: 0.3655\n",
            "Epoch 18/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8044 - loss: 0.4596 - val_accuracy: 0.9000 - val_loss: 0.3430\n",
            "Epoch 19/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8485 - loss: 0.4341 - val_accuracy: 0.9000 - val_loss: 0.3209\n",
            "Epoch 20/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8621 - loss: 0.4338 - val_accuracy: 0.9000 - val_loss: 0.3015\n",
            "Epoch 21/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8523 - loss: 0.4321 - val_accuracy: 0.9000 - val_loss: 0.2843\n",
            "Epoch 22/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8304 - loss: 0.4229 - val_accuracy: 0.9000 - val_loss: 0.2688\n",
            "Epoch 23/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8131 - loss: 0.4103 - val_accuracy: 0.9000 - val_loss: 0.2560\n",
            "Epoch 24/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8894 - loss: 0.3460 - val_accuracy: 0.9000 - val_loss: 0.2424\n",
            "Epoch 25/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8725 - loss: 0.3827 - val_accuracy: 0.9000 - val_loss: 0.2305\n",
            "Epoch 26/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8815 - loss: 0.3307 - val_accuracy: 0.9333 - val_loss: 0.2195\n",
            "Epoch 27/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8148 - loss: 0.3827 - val_accuracy: 0.9667 - val_loss: 0.2094\n",
            "Epoch 28/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8410 - loss: 0.3588 - val_accuracy: 0.9667 - val_loss: 0.2017\n",
            "Epoch 29/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8919 - loss: 0.3085 - val_accuracy: 0.9667 - val_loss: 0.1922\n",
            "Epoch 30/30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8548 - loss: 0.2947 - val_accuracy: 0.9667 - val_loss: 0.1837\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9667 - loss: 0.1837\n",
            "Dokładność na zbiorze testowym (Dense IRIS): 0.97\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 39ms/step - accuracy: 0.9342 - loss: 0.2210 - val_accuracy: 0.9751 - val_loss: 0.0820\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 39ms/step - accuracy: 0.9871 - loss: 0.0425 - val_accuracy: 0.9880 - val_loss: 0.0382\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 38ms/step - accuracy: 0.9911 - loss: 0.0284 - val_accuracy: 0.9848 - val_loss: 0.0478\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 37ms/step - accuracy: 0.9923 - loss: 0.0251 - val_accuracy: 0.9879 - val_loss: 0.0443\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 38ms/step - accuracy: 0.9945 - loss: 0.0168 - val_accuracy: 0.9877 - val_loss: 0.0485\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.0609\n",
            "Dokładność na zbiorze testowym (CNN MNIST): 0.99\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 414ms/step - accuracy: 0.6936 - loss: 0.5490 - val_accuracy: 0.7388 - val_loss: 0.5196\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 419ms/step - accuracy: 0.8695 - loss: 0.3113 - val_accuracy: 0.8643 - val_loss: 0.3191\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 417ms/step - accuracy: 0.9250 - loss: 0.2015 - val_accuracy: 0.8854 - val_loss: 0.2843\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 410ms/step - accuracy: 0.9525 - loss: 0.1352 - val_accuracy: 0.8750 - val_loss: 0.3603\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 410ms/step - accuracy: 0.9711 - loss: 0.0861 - val_accuracy: 0.8716 - val_loss: 0.3655\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 60ms/step - accuracy: 0.8686 - loss: 0.3714\n",
            "Dokładność na zbiorze testowym (GRU IMDB): 0.87\n",
            "Epoch 1/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - loss: 0.2554\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 196ms/step - loss: 0.0958\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - loss: 0.0891\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 180ms/step - loss: 0.0886\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - loss: 0.0880\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 163ms/step - loss: 0.0877\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 0.0872\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - loss: 0.0868\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - loss: 0.0867\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - loss: 0.0864\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0858\n",
            "Błąd średniokwadratowy na danych testowych (Transformer): 0.0858\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dense_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "dense_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_dense = dense_model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))\n",
        "\n",
        "loss, acc = dense_model.evaluate(X_test, y_test)\n",
        "print(f\"Dokładność na zbiorze testowym (Dense IRIS): {acc:.2f}\")\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train[..., tf.newaxis] / 255.0\n",
        "x_test = x_test[..., tf.newaxis] / 255.0\n",
        "\n",
        "cnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_cnn = cnn_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "loss, acc = cnn_model.evaluate(x_test, y_test)\n",
        "print(f\"Dokładność na zbiorze testowym (CNN MNIST): {acc:.2f}\")\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)\n",
        "\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=500)\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=500)\n",
        "\n",
        "gru_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=10000, output_dim=32),\n",
        "    tf.keras.layers.GRU(64),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "gru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_gru = gru_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "loss, acc = gru_model.evaluate(x_test, y_test)\n",
        "print(f\"Dokładność na zbiorze testowym (GRU IMDB): {acc:.2f}\")\n",
        "\n",
        "X = np.random.rand(1000, 10, 512)\n",
        "Y = np.random.rand(1000, 512)\n",
        "\n",
        "def build_transformer_encoder(num_layers=2, num_heads=2, key_dim=64, input_shape=(10, 512)):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_layers):\n",
        "        attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)\n",
        "        attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
        "        ffn_output = tf.keras.layers.Dense(512, activation='relu')(attn_output)\n",
        "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + ffn_output)\n",
        "    outputs = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = tf.keras.layers.Dense(512, activation='linear')(outputs)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "transformer_model = build_transformer_encoder()\n",
        "\n",
        "transformer_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history_transformer = transformer_model.fit(X, Y, epochs=10, batch_size=32)\n",
        "\n",
        "loss = transformer_model.evaluate(X, Y)\n",
        "print(f\"Błąd średniokwadratowy na danych testowych (Transformer): {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9b-RBqAtFplM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}